{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flowers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaqvTZz+xqO2KoEYWhdjt3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baroodb/code/blob/main/flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AveqSFMBdRaM"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import  Path\n",
        "import "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZRBhMOucE5k"
      },
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTQOCHmwdfEf",
        "outputId": "5409e572-1331-472d-cafa-f753167841ed"
      },
      "source": [
        "data_path = tf.keras.utils.get_file(origin=url, fname='flower_photos', untar=True)\n",
        "print(data_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 3s 0us/step\n",
            "228827136/228813984 [==============================] - 3s 0us/step\n",
            "/root/.keras/datasets/flower_photos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX4UwoZKf4XR",
        "outputId": "124b8b4e-7f6f-4e16-ba91-1eff7c6d261f"
      },
      "source": [
        "path = Path(data_path)\n",
        "path"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp7z4emjgYaB"
      },
      "source": [
        "entries = path.glob(pattern='*')\n",
        "for entry in entries:\n",
        "  if os.path.isfile(entry):\n",
        "    Path(entry).unlink()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elsCwkWekqDj",
        "outputId": "bdfcabe7-93b0-4dbf-d4c4-17af233ab792"
      },
      "source": [
        "class_names = os.listdir(path)\n",
        "class_names"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daisy', 'roses', 'dandelion', 'tulips', 'sunflowers']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z8oniKak76B",
        "outputId": "9b17b862-29a6-4f09-e42a-d72e9fa5eb0e"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(path/'*/*'), shuffle=False)\n",
        "list_ds"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.string>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q41n1uOo3zHT"
      },
      "source": [
        "def _get_labels(filename):\n",
        "  parts = tf.strings.split(filename, os.path.sep)\n",
        "  onehot = parts[-2] == class_names\n",
        "  return tf.argmax(onehot)\n",
        "\n",
        "def _process_image(filename):\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  return image\n",
        "\n",
        "def process_path(filename):\n",
        "  label = _get_labels(filename)\n",
        "  image = _process_image(filename)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def configure_for_perf(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=5000)\n",
        "  ds = ds.batch(32)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "  return ds\n",
        "\n",
        "def get_datasets(path, val_size=400):\n",
        "  filenames = tf.data.Dataset.list_files(file_pattern=str(path/'*/*'), shuffle=False)\n",
        "  filenames = filenames.shuffle(buffer_size=5000, reshuffle_each_iteration=False)\n",
        "  train_files = filenames.skip(val_size)\n",
        "  val_files = filenames.take(val_size)\n",
        "  return train_files, val_files"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqyxMChMDSnZ"
      },
      "source": [
        "# build my  data pipeline \n",
        "train_files, val_files = get_datasets(path)\n",
        "\n",
        "train_ds = train_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = configure_for_perf(train_ds)\n",
        "val_ds = configure_for_perf(val_ds)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8O2NFYCxwvF"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "input_shape = (224, 224, 3)\n",
        "data_augmentation = tf.keras.Sequential(\n",
        "  [\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
        "                                                 input_shape=input_shape),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "\n",
        "def build_model(input_shape):\n",
        "  inputs = Input(input_shape)\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(inputs)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  \n",
        "  outputs = Dense(5)(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'], \n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkPwWc55HRd-"
      },
      "source": [
        "from tensorflow.keras import Sequential, layers\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(5)\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'], \n",
        "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dhK5fPC1Cob",
        "outputId": "ee0144bd-1af2-4f0d-c87b-948f81cb2eb6"
      },
      "source": [
        "#model = build_model((224, 224, 3))\n",
        "\n",
        "H = model.fit(train_ds, \n",
        "              validation_data=val_ds,\n",
        "              epochs=10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 43s 81ms/step - loss: 1.2553 - accuracy: 0.4682 - val_loss: 1.0816 - val_accuracy: 0.5900\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.9814 - accuracy: 0.6174 - val_loss: 1.0024 - val_accuracy: 0.6175\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 7s 67ms/step - loss: 0.8820 - accuracy: 0.6572 - val_loss: 0.7978 - val_accuracy: 0.7025\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.8115 - accuracy: 0.6905 - val_loss: 0.7532 - val_accuracy: 0.7150\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 7s 67ms/step - loss: 0.7873 - accuracy: 0.7076 - val_loss: 0.8331 - val_accuracy: 0.7150\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 7s 67ms/step - loss: 0.7092 - accuracy: 0.7303 - val_loss: 0.7272 - val_accuracy: 0.7175\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.7059 - accuracy: 0.7306 - val_loss: 0.7083 - val_accuracy: 0.7350\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.6530 - accuracy: 0.7428 - val_loss: 0.6908 - val_accuracy: 0.7550\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 7s 67ms/step - loss: 0.6503 - accuracy: 0.7547 - val_loss: 0.7258 - val_accuracy: 0.7400\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 7s 68ms/step - loss: 0.6148 - accuracy: 0.7670 - val_loss: 0.6853 - val_accuracy: 0.7375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipofG-A5gqKx"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9P6Tn4QeCoT",
        "outputId": "8619ee79-96ea-438d-9ee8-dd332ede67a1"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "base_model = MobileNetV2(include_top=False)\n",
        "base_model.trainable = False"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTd3-8VgemXV"
      },
      "source": [
        "inputs = Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(5)(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB55cKR4j3lQ"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "              metrics=['accuracy'], \n",
        "              loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTfAZ_eRkBbc",
        "outputId": "9fd14f9c-8c40-4047-8f40-565fa368a569"
      },
      "source": [
        "H = model.fit(train_ds, \n",
        "              validation_data=val_ds,\n",
        "              epochs=10)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 15s 112ms/step - loss: 1.8612 - accuracy: 0.2312 - val_loss: 1.6037 - val_accuracy: 0.2825\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 11s 102ms/step - loss: 1.6333 - accuracy: 0.2761 - val_loss: 1.7194 - val_accuracy: 0.2450\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 11s 102ms/step - loss: 1.6482 - accuracy: 0.2963 - val_loss: 1.9482 - val_accuracy: 0.2650\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 10s 101ms/step - loss: 1.6834 - accuracy: 0.3076 - val_loss: 1.8019 - val_accuracy: 0.2550\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 10s 102ms/step - loss: 1.6596 - accuracy: 0.3128 - val_loss: 1.8325 - val_accuracy: 0.4100\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 10s 101ms/step - loss: 1.5514 - accuracy: 0.3462 - val_loss: 1.4384 - val_accuracy: 0.3825\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 10s 101ms/step - loss: 1.5452 - accuracy: 0.3505 - val_loss: 1.6478 - val_accuracy: 0.3725\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 10s 102ms/step - loss: 1.5553 - accuracy: 0.3480 - val_loss: 1.5893 - val_accuracy: 0.3250\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 10s 101ms/step - loss: 1.5747 - accuracy: 0.3483 - val_loss: 1.6674 - val_accuracy: 0.3250\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 11s 102ms/step - loss: 1.5486 - accuracy: 0.3716 - val_loss: 1.5829 - val_accuracy: 0.3300\n"
          ]
        }
      ]
    }
  ]
}