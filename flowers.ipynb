{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flowers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSx1wRaiJnGTKIksKnAyX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baroodb/code/blob/main/flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AveqSFMBdRaM"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import  Path"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZRBhMOucE5k"
      },
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTQOCHmwdfEf",
        "outputId": "701558fc-2bc9-48a5-9962-de94ac9a1041"
      },
      "source": [
        "data_path = tf.keras.utils.get_file(origin=url, fname='flower_photos', untar=True)\n",
        "print(data_path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228818944/228813984 [==============================] - 3s 0us/step\n",
            "228827136/228813984 [==============================] - 3s 0us/step\n",
            "/root/.keras/datasets/flower_photos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX4UwoZKf4XR",
        "outputId": "df8533bd-623a-4446-c85b-90d7b65b967a"
      },
      "source": [
        "path = Path(data_path)\n",
        "path"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp7z4emjgYaB"
      },
      "source": [
        "entries = path.glob(pattern='*')\n",
        "for entry in entries:\n",
        "  if os.path.isfile(entry):\n",
        "    Path(entry).unlink()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elsCwkWekqDj",
        "outputId": "2e03fda0-7459-42aa-be04-f47f3c1eaee5"
      },
      "source": [
        "class_names = os.listdir(path)\n",
        "class_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['daisy', 'roses', 'dandelion', 'tulips', 'sunflowers']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z8oniKak76B",
        "outputId": "2997d949-fc79-45f1-a5cc-1aa75174f276"
      },
      "source": [
        "list_ds = tf.data.Dataset.list_files(str(path/'*/*'), shuffle=False)\n",
        "list_ds"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.string>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q41n1uOo3zHT"
      },
      "source": [
        "def _get_labels(filename):\n",
        "  parts = tf.strings.split(filename, os.path.sep)\n",
        "  onehot = parts[-2] == class_names\n",
        "  return tf.argmax(onehot)\n",
        "\n",
        "def _process_image(filename):\n",
        "  image = tf.io.read_file(filename)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  image = tf.image.resize(image, [224, 224])\n",
        "  return image\n",
        "\n",
        "def process_path(filename):\n",
        "  label = _get_labels(filename)\n",
        "  image = _process_image(filename)\n",
        "\n",
        "  return image, label\n",
        "\n",
        "def configure_for_perf(ds):\n",
        "  ds = ds.cache()\n",
        "  ds = ds.shuffle(buffer_size=5000)\n",
        "  ds = ds.batch(32)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "  return ds\n",
        "\n",
        "def get_datasets(path, val_size=400):\n",
        "  filenames = tf.data.Dataset.list_files(file_pattern=str(path/'*/*'), shuffle=False)\n",
        "  filenames = filenames.shuffle(buffer_size=5000, reshuffle_each_iteration=False)\n",
        "  train_files = filenames.skip(val_size)\n",
        "  val_files = filenames.take(val_size)\n",
        "  return train_files, val_files"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqyxMChMDSnZ"
      },
      "source": [
        "# build my  data pipeline \n",
        "train_files, val_files = get_datasets(path)\n",
        "\n",
        "train_ds = train_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_files.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_ds = configure_for_perf(train_ds)\n",
        "val_ds = configure_for_perf(val_ds)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8O2NFYCxwvF"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_model(input_shape):\n",
        "  inputs = Input(input_shape)\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(inputs)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = MaxPool2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  \n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64, activation='relu')(x)\n",
        "  \n",
        "  outputs = Dense(5)(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'], \n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dhK5fPC1Cob",
        "outputId": "ec424468-3d29-4c70-af7a-f585f0cc1c76"
      },
      "source": [
        "model = build_model((224, 224, 3))\n",
        "\n",
        "H = model.fit(train_ds, \n",
        "              validation_data=val_ds,\n",
        "              epochs=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "103/103 [==============================] - 70s 309ms/step - loss: 1.4348 - accuracy: 0.3645 - val_loss: 1.2168 - val_accuracy: 0.4700\n",
            "Epoch 2/10\n",
            "103/103 [==============================] - 28s 277ms/step - loss: 1.1224 - accuracy: 0.5382 - val_loss: 1.0700 - val_accuracy: 0.5675\n",
            "Epoch 3/10\n",
            "103/103 [==============================] - 28s 276ms/step - loss: 1.0440 - accuracy: 0.5856 - val_loss: 1.0330 - val_accuracy: 0.5650\n",
            "Epoch 4/10\n",
            "103/103 [==============================] - 29s 277ms/step - loss: 0.9159 - accuracy: 0.6511 - val_loss: 0.9188 - val_accuracy: 0.6525\n",
            "Epoch 5/10\n",
            "103/103 [==============================] - 29s 277ms/step - loss: 0.7047 - accuracy: 0.7275 - val_loss: 0.9279 - val_accuracy: 0.6450\n",
            "Epoch 6/10\n",
            "103/103 [==============================] - 29s 277ms/step - loss: 0.4834 - accuracy: 0.8300 - val_loss: 1.0826 - val_accuracy: 0.6400\n",
            "Epoch 7/10\n",
            "103/103 [==============================] - 29s 277ms/step - loss: 0.3136 - accuracy: 0.8936 - val_loss: 1.2880 - val_accuracy: 0.6100\n",
            "Epoch 8/10\n",
            "103/103 [==============================] - 29s 277ms/step - loss: 0.1978 - accuracy: 0.9373 - val_loss: 1.6489 - val_accuracy: 0.6225\n",
            "Epoch 9/10\n",
            "103/103 [==============================] - 29s 277ms/step - loss: 0.1099 - accuracy: 0.9630 - val_loss: 1.7787 - val_accuracy: 0.6575\n",
            "Epoch 10/10\n",
            "103/103 [==============================] - 29s 278ms/step - loss: 0.1190 - accuracy: 0.9670 - val_loss: 1.9769 - val_accuracy: 0.6500\n"
          ]
        }
      ]
    }
  ]
}